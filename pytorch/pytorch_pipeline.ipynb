{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a7d5d4-e9c3-4bb0-9f10-2f593de86d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3778efc5-493c-4ca3-883e-03e6208444ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../baselines/RNN/datasets/Dataset 1.csv') #to be comparable with the size of other datasets, select ~5000 data points from the reference\n",
    "df['TRIMER_mol'] = df['TRIMER'].apply(Chem.MolFromSmiles)\n",
    "df = df.dropna()\n",
    "#df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8ffff8-98b7-4def-b85a-00ebd877b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 1024\n",
    "fp = df['TRIMER_mol'].apply(lambda m: AllChem.GetMorganFingerprintAsBitVect(m, radius=3, nBits=nbits))\n",
    "df['fps'] = fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6bc084-969c-453c-890e-f60e6de764c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIMER', 'Excitation Energy (eV)', 'IP (eV)', 'EA (eV)',\n",
       "       'Calib. IP (eV)', 'Calib. EA (eV)', 'Calib. Excitation Energy (eV)',\n",
       "       'TRIMER_mol', 'fps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37445a2d-93fc-4e48-a07c-85a1edc202b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de410120-2931-4218-94f9-de436ecb9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrimerDataset(Dataset):\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tokens = self.data.loc[index, \"fps\"]\n",
    "        target = self.data.loc[index, self.target_column]\n",
    "\n",
    "        tokens_tensor = torch.tensor(tokens, dtype=torch.long)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "        return tokens_tensor, target_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db7c6c9-1b1d-4896-923d-93811a55869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"EA (eV)\"\n",
    "train_dataset = TrimerDataset(train_data, target_column)\n",
    "test_dataset = TrimerDataset(test_data, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b254fa-fefb-4a90-92db-9ba9f84f08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "shuffle = True\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cfd912-4e78-4987-9925-a0eb649d057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8abb83e-2950-4cc4-a4e7-acbe369470b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Tokens: tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "Target: 2.458224058151245\n",
      "\n",
      "Sample 2:\n",
      "Tokens: tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Target: 1.7806440591812134\n",
      "\n",
      "Sample 3:\n",
      "Tokens: tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Target: 1.791316032409668\n",
      "\n",
      "Sample 4:\n",
      "Tokens: tensor([0, 1, 0,  ..., 0, 1, 0])\n",
      "Target: 1.6426440477371216\n",
      "\n",
      "Sample 5:\n",
      "Tokens: tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Target: 2.719320058822632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    tokens, target = train_dataset[i]\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Target: {target}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843dfd92-cf98-4fca-bb62-6624146202d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without mlp.\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim, lstm_dim, linear_dim, out_dim, num_tokens=None):\n",
    "        super(RNN, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.emb = nn.Embedding(num_tokens, emb_dim) if num_tokens is not None else None\n",
    "        self.lstm1 = nn.LSTM(emb_dim, lstm_dim, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(lstm_dim*2, lstm_dim, bidirectional=True, batch_first=True)\n",
    "        self.lstm_dim = lstm_dim\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(seq_len * lstm_dim * 2, linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(linear_dim, out_dim),\n",
    "        )\n",
    "        \n",
    "        self.last = nn.Linear(lstm_dim * seq_len *2, out_dim)\n",
    "\n",
    "    def forward(self, data):  # 2D\n",
    "        x = self.emb(data) if self.emb else data\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        # x = x.reshape(x.shape[0], -1)  # Flatten time and batch dims\n",
    "        # x = self.mlp(x) removed mlp\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten time dim into last one (instead of before into sample dim)\n",
    "        #x = self.mlp(x)\n",
    "        x = self.last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ebae80-cc0c-459b-a783-cf89d27ed646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Veronika\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim, lstm_dim, linear_dim, out_dim, num_tokens=None):\n",
    "        super(RNN, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.emb = nn.Embedding(num_tokens, emb_dim) if num_tokens is not None else None\n",
    "        self.lstm1 = nn.LSTM(emb_dim, lstm_dim, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(lstm_dim*2, lstm_dim, bidirectional=True, batch_first=True)\n",
    "        self.lstm_dim = lstm_dim\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(lstm_dim * 2, int(lstm_dim/2)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.last = nn.Linear(int(lstm_dim/2)*seq_len, out_dim)\n",
    "\n",
    "    def forward(self, data):  # 2D\n",
    "        x = self.emb(data) if self.emb else data\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        # x = x.reshape(x.shape[0], -1)  # Flatten time and batch dims\n",
    "        x = self.mlp(x) #removed mlp\n",
    "        #x = x.reshape(x.shape[0], -1)  # Flatten time dim into last one (instead of before into sample dim)\n",
    "        x = x.reshape(-1, int(self.lstm_dim/2) * self.seq_len)\n",
    "        #x = self.mlp(x)\n",
    "        x = self.last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2292b5d8-edd4-4f93-b492-e4b9b98a9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1024\n",
    "emb_dim = 100 #50, 100, 200, or 300\n",
    "lstm_dim= 20 #50, 100, 200\n",
    "linear_dim = 100\n",
    "out_dim = 1\n",
    "num_tokens=1024\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = RNN(seq_len, emb_dim, lstm_dim, linear_dim, out_dim, num_tokens).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddff0f15-ae0e-4324-8a2a-1595dce9121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_RNN(model, train_loader, test_loader, loss_fn, optimizer, num_epochs=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        #for x, y in train_loader:\n",
    "        for x, y in tqdm(train_loader, desc=f'Training epoch {epoch + 1}/{num_epochs}'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                output = model(x)\n",
    "                loss = loss_fn(output, y)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d3f8b-a201-4a16-8528-014e9efbb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/120:   0%|          | 0/300 [00:00<?, ?it/s]/home/zmao_umass_edu/.conda/envs/figo/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Training epoch 1/120: 100%|█████████▉| 299/300 [01:07<00:00,  4.41it/s]/home/zmao_umass_edu/.conda/envs/figo/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([118])) that is different to the input size (torch.Size([118, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Training epoch 1/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n",
      "/home/zmao_umass_edu/.conda/envs/figo/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([126])) that is different to the input size (torch.Size([126, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Train Loss: 0.4808, Test Loss: 0.4343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120, Train Loss: 0.4423, Test Loss: 0.4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120, Train Loss: 0.4434, Test Loss: 0.4434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120, Train Loss: 0.4393, Test Loss: 0.4448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 5/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/120, Train Loss: 0.4400, Test Loss: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 6/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/120, Train Loss: 0.4377, Test Loss: 0.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 7/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/120, Train Loss: 0.4422, Test Loss: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 8/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/120, Train Loss: 0.4386, Test Loss: 0.4396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 9/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/120, Train Loss: 0.4388, Test Loss: 0.4421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 10/120: 100%|██████████| 300/300 [01:08<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/120, Train Loss: 0.4379, Test Loss: 0.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 11/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/120, Train Loss: 0.4386, Test Loss: 0.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 12/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120, Train Loss: 0.4387, Test Loss: 0.4397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 13/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/120, Train Loss: 0.4371, Test Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 14/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120, Train Loss: 0.4390, Test Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 15/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120, Train Loss: 0.4387, Test Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 16/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/120, Train Loss: 0.4388, Test Loss: 0.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 17/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/120, Train Loss: 0.4381, Test Loss: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 18/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/120, Train Loss: 0.4375, Test Loss: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 19/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/120, Train Loss: 0.4379, Test Loss: 0.4350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 20/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/120, Train Loss: 0.4387, Test Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 21/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120, Train Loss: 0.4376, Test Loss: 0.4373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 22/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120, Train Loss: 0.4392, Test Loss: 0.4497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 23/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/120, Train Loss: 0.4372, Test Loss: 0.4388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 24/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/120, Train Loss: 0.4381, Test Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 25/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/120, Train Loss: 0.4398, Test Loss: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 26/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120, Train Loss: 0.4374, Test Loss: 0.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 27/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120, Train Loss: 0.4373, Test Loss: 0.4368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 28/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/120, Train Loss: 0.4387, Test Loss: 0.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 29/120: 100%|██████████| 300/300 [01:08<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120, Train Loss: 0.4376, Test Loss: 0.4391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 30/120: 100%|██████████| 300/300 [01:08<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/120, Train Loss: 0.4374, Test Loss: 0.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 31/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120, Train Loss: 0.4372, Test Loss: 0.4343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 32/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/120, Train Loss: 0.4375, Test Loss: 0.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 33/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/120, Train Loss: 0.4374, Test Loss: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 34/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/120, Train Loss: 0.4372, Test Loss: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 35/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/120, Train Loss: 0.4378, Test Loss: 0.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 36/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/120, Train Loss: 0.4371, Test Loss: 0.4510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 37/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120, Train Loss: 0.4370, Test Loss: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 38/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/120, Train Loss: 0.4392, Test Loss: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 39/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/120, Train Loss: 0.4379, Test Loss: 0.4341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 40/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/120, Train Loss: 0.4365, Test Loss: 0.4362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 41/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120, Train Loss: 0.4367, Test Loss: 0.4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 42/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/120, Train Loss: 0.4383, Test Loss: 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 43/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120, Train Loss: 0.4375, Test Loss: 0.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 44/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/120, Train Loss: 0.4370, Test Loss: 0.4360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 45/120: 100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/120, Train Loss: 0.4375, Test Loss: 0.4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 46/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/120, Train Loss: 0.4367, Test Loss: 0.4428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 47/120: 100%|██████████| 300/300 [01:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/120, Train Loss: 0.4379, Test Loss: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 48/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/120, Train Loss: 0.4370, Test Loss: 0.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 49/120: 100%|██████████| 300/300 [01:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/120, Train Loss: 0.4369, Test Loss: 0.4341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 50/120: 100%|██████████| 300/300 [01:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/120, Train Loss: 0.4375, Test Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 51/120: 100%|██████████| 300/300 [01:08<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120, Train Loss: 0.4368, Test Loss: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 52/120: 100%|██████████| 300/300 [01:08<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/120, Train Loss: 0.4369, Test Loss: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 53/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/120, Train Loss: 0.4383, Test Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 54/120: 100%|██████████| 300/300 [01:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/120, Train Loss: 0.4371, Test Loss: 0.4366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 55/120: 100%|██████████| 300/300 [01:07<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/120, Train Loss: 0.4360, Test Loss: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 56/120: 100%|██████████| 300/300 [01:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120, Train Loss: 0.4371, Test Loss: 0.4402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 57/120:  98%|█████████▊| 293/300 [01:06<00:01,  4.42it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 120\n",
    "train_losses, test_losses = train_RNN(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8562d-547e-46af-be7a-64dc3dcb965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = f\"model_{current_time}.pt\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Saved PyTorch Model State to \"+model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ff4fc-1091-4d53-b857-a7de4ec7f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            output = model(x)\n",
    "            all_outputs.extend(output.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "    return np.array(all_outputs), np.array(all_targets)\n",
    "\n",
    "# Evaluate the model\n",
    "predicted, targets = evaluate_model(model, test_dataloader, device)\n",
    "\n",
    "# Calculate R2 score, MAE, and RMSE\n",
    "r2 = r2_score(targets, predicted)\n",
    "mae = mean_absolute_error(targets, predicted)\n",
    "rmse = np.sqrt(mean_squared_error(targets, predicted))\n",
    "\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609609ed-76f7-4ca7-ba96-fa8e34c13af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_np = np.array(targets).flatten()\n",
    "predicted_np = np.array(predicted).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(predicted_np, targets_np, alpha=0.5)\n",
    "\n",
    "# Fit a linear regression model\n",
    "m, b = np.polyfit(predicted_np, targets_np, 1)\n",
    "\n",
    "# Create line points based on the min and max of the predicted values\n",
    "line_x = np.linspace(min(predicted_np), max(predicted_np), 100)\n",
    "line_y = m * line_x + b\n",
    "\n",
    "# Plot the best fit line\n",
    "plt.plot(line_x, line_y, '--', c='r')\n",
    "\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.title('Scatter plot of Predicted vs. True Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb865dff-fa65-4bc0-a64d-bc4bdf865522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-figo)",
   "language": "python",
   "name": "conda-env-.conda-figo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
